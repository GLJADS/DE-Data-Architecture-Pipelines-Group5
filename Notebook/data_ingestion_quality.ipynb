{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b8ca9db-68bc-49d6-a69d-ed5e2b88c17e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session started.\n",
      "\n",
      "Loaded table: Movies\n",
      "root\n",
      " |-- movie_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- content_type: string (nullable = true)\n",
      " |-- genre_primary: string (nullable = true)\n",
      " |-- genre_secondary: string (nullable = true)\n",
      " |-- release_year: long (nullable = true)\n",
      " |-- duration_minutes: double (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- country_of_origin: string (nullable = true)\n",
      " |-- imdb_rating: double (nullable = true)\n",
      " |-- production_budget: double (nullable = true)\n",
      " |-- box_office_revenue: double (nullable = true)\n",
      " |-- number_of_seasons: double (nullable = true)\n",
      " |-- number_of_episodes: double (nullable = true)\n",
      " |-- is_netflix_original: boolean (nullable = true)\n",
      " |-- added_to_platform: date (nullable = true)\n",
      " |-- content_warning: boolean (nullable = true)\n",
      "\n",
      "\n",
      "Loaded table: Users\n",
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- state_province: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- subscription_plan: string (nullable = true)\n",
      " |-- subscription_start_date: date (nullable = true)\n",
      " |-- is_active: boolean (nullable = true)\n",
      " |-- monthly_spend: double (nullable = true)\n",
      " |-- primary_device: string (nullable = true)\n",
      " |-- household_size: double (nullable = true)\n",
      " |-- created_at: timestamp (nullable = true)\n",
      "\n",
      "\n",
      "Loaded table: Watch_history\n",
      "root\n",
      " |-- session_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- movie_id: string (nullable = true)\n",
      " |-- watch_date: date (nullable = true)\n",
      " |-- device_type: string (nullable = true)\n",
      " |-- watch_duration_minutes: double (nullable = true)\n",
      " |-- progress_percentage: double (nullable = true)\n",
      " |-- action: string (nullable = true)\n",
      " |-- quality: string (nullable = true)\n",
      " |-- location_country: string (nullable = true)\n",
      " |-- is_download: boolean (nullable = true)\n",
      " |-- user_rating: long (nullable = true)\n",
      "\n",
      "\n",
      "Loaded table: Reviews\n",
      "root\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- movie_id: string (nullable = true)\n",
      " |-- rating: long (nullable = true)\n",
      " |-- review_date: date (nullable = true)\n",
      " |-- device_type: string (nullable = true)\n",
      " |-- is_verified_watch: boolean (nullable = true)\n",
      " |-- helpful_votes: double (nullable = true)\n",
      " |-- total_votes: double (nullable = true)\n",
      " |-- review_text: string (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      " |-- sentiment_score: double (nullable = true)\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import avg, col, count, desc\n",
    "\n",
    "# =========================================\n",
    "# 0. START SPARK SESSION\n",
    "# =========================================\n",
    "\n",
    "# Configuration\n",
    "project_id = \"dejadsgl\"\n",
    "bq_dataset = \"netflix\"\n",
    "temp_bucket = \"netflix-group5-temp_gl\"\n",
    "gcs_data_bucket = \"netflix_data_25\"\n",
    "\n",
    "# Spark configuration\n",
    "sparkConf = SparkConf()\n",
    "sparkConf.setMaster(\"spark://spark-master:7077\")\n",
    "sparkConf.setAppName(\"SparkCleanDataset\")\n",
    "sparkConf.set(\"spark.driver.memory\", \"2g\")\n",
    "sparkConf.set(\"spark.executor.cores\", \"1\")\n",
    "sparkConf.set(\"spark.driver.cores\", \"1\")\n",
    "\n",
    "# Create the Spark session\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "\n",
    "# Use the Cloud Storage bucket for temporary BigQuery export data used by the connector\n",
    "spark.conf.set('temporaryGcsBucket', temp_bucket)\n",
    "\n",
    "# Setup hadoop fs configuration for schema gs://\n",
    "conf = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "conf.set(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "\n",
    "print(\"Spark session started.\")\n",
    "\n",
    "# =========================================\n",
    "# 1. LOAD ALL TABLES\n",
    "# =========================================\n",
    "\n",
    "# Load data from BigQuery\n",
    "tables = {}\n",
    "titles = [\n",
    "    \"Movies\",\n",
    "    \"Users\",\n",
    "    \"Watch_history\",\n",
    "    \"Reviews\"\n",
    "]\n",
    "\n",
    "for title in titles:\n",
    "    df = spark.read \\\n",
    "            .format(\"bigquery\") \\\n",
    "            .load(f\"{project_id}.{bq_dataset}.{title}\")\n",
    "\n",
    "    df.cache()\n",
    "    tables[title] = df   # store in dictionary\n",
    "\n",
    "    print(f\"\\nLoaded table: {title}\")\n",
    "    df.printSchema()\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f2fd9e7f-7166-458f-b79c-effe9da588bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Cleaning table: Movies ==========\n",
      "\n",
      "STEP 0: Starting data-cleaning pipeline...\n",
      "Initial row count: 1040\n",
      "\n",
      "STEP 1: Handling missing values\n",
      " - Imputing numerical columns: ['release_year', 'duration_minutes', 'imdb_rating', 'production_budget', 'box_office_revenue', 'number_of_seasons', 'number_of_episodes']\n",
      "   Completed numerical imputation.\n",
      "   Row count after numeric imputation: 1040\n",
      " - Imputing categorical columns: ['movie_id', 'title', 'content_type', 'genre_primary', 'genre_secondary', 'rating', 'language', 'country_of_origin']\n",
      "   Filled missing values in 'movie_id' with mode='movie_0823'\n",
      "   Filled missing values in 'title' with mode='A Adventure'\n",
      "   Filled missing values in 'content_type' with mode='Movie'\n",
      "   Filled missing values in 'genre_primary' with mode='Adventure'\n",
      "   Filled missing values in 'rating' with mode='TV-Y'\n",
      "   Filled missing values in 'language' with mode='English'\n",
      "   Filled missing values in 'country_of_origin' with mode='USA'\n",
      "   Completed categorical imputation.\n",
      "   Row count after categorical imputation: 1040\n",
      "\n",
      "STEP 2: Removing duplicates\n",
      " - No suitable duplicate keys found, skipping deduplication.\n",
      "\n",
      "STEP 3: Filtering outliers using IQR method\n",
      "   - Processing outliers for numeric column 'release_year'\n",
      "     Removed 11 outliers from 'release_year'\n",
      "     New row count: 1029\n",
      "   - Processing outliers for numeric column 'duration_minutes'\n",
      "     Removed 25 outliers from 'duration_minutes'\n",
      "     New row count: 1004\n",
      "   - Processing outliers for numeric column 'imdb_rating'\n",
      "     Removed 55 outliers from 'imdb_rating'\n",
      "     New row count: 949\n",
      "   - Processing outliers for numeric column 'production_budget'\n",
      "     Removed 330 outliers from 'production_budget'\n",
      "     New row count: 619\n",
      "   - Processing outliers for numeric column 'box_office_revenue'\n",
      "     Removed 60 outliers from 'box_office_revenue'\n",
      "     New row count: 559\n",
      "   - Processing outliers for numeric column 'number_of_seasons'\n",
      "     Removed 261 outliers from 'number_of_seasons'\n",
      "     New row count: 298\n",
      "   - Processing outliers for numeric column 'number_of_episodes'\n",
      "     Removed 41 outliers from 'number_of_episodes'\n",
      "     New row count: 257\n",
      "\n",
      "STEP 4: Pipeline completed for table: Movies\n",
      "Final schema:\n",
      "root\n",
      " |-- movie_id: string (nullable = false)\n",
      " |-- title: string (nullable = false)\n",
      " |-- content_type: string (nullable = false)\n",
      " |-- genre_primary: string (nullable = false)\n",
      " |-- genre_secondary: string (nullable = true)\n",
      " |-- rating: string (nullable = false)\n",
      " |-- language: string (nullable = false)\n",
      " |-- country_of_origin: string (nullable = false)\n",
      " |-- is_netflix_original: boolean (nullable = true)\n",
      " |-- added_to_platform: date (nullable = true)\n",
      " |-- content_warning: boolean (nullable = true)\n",
      " |-- release_year: long (nullable = true)\n",
      " |-- duration_minutes: double (nullable = true)\n",
      " |-- imdb_rating: double (nullable = true)\n",
      " |-- production_budget: double (nullable = true)\n",
      " |-- box_office_revenue: double (nullable = true)\n",
      " |-- number_of_seasons: double (nullable = true)\n",
      " |-- number_of_episodes: double (nullable = true)\n",
      "\n",
      "\n",
      "========== Cleaning table: Users ==========\n",
      "\n",
      "STEP 0: Starting data-cleaning pipeline...\n",
      "Initial row count: 10300\n",
      "\n",
      "STEP 1: Handling missing values\n",
      " - Imputing numerical columns: ['age', 'monthly_spend', 'household_size']\n",
      "   Completed numerical imputation.\n",
      "   Row count after numeric imputation: 10300\n",
      " - Imputing categorical columns: ['user_id', 'email', 'first_name', 'last_name', 'gender', 'country', 'state_province', 'city', 'subscription_plan', 'primary_device']\n",
      "   Filled missing values in 'user_id' with mode='user_09536'\n",
      "   Filled missing values in 'email' with mode='wadetyler@example.org'\n",
      "   Filled missing values in 'first_name' with mode='Michael'\n",
      "   Filled missing values in 'last_name' with mode='Smith'\n",
      "   Filled missing values in 'gender' with mode='Female'\n",
      "   Filled missing values in 'country' with mode='USA'\n",
      "   Filled missing values in 'state_province' with mode='North Carolina'\n",
      "   Filled missing values in 'city' with mode='North Michael'\n",
      "   Filled missing values in 'subscription_plan' with mode='Standard'\n",
      "   Filled missing values in 'primary_device' with mode='Desktop'\n",
      "   Completed categorical imputation.\n",
      "   Row count after categorical imputation: 10300\n",
      "\n",
      "STEP 2: Removing duplicates\n",
      " - No suitable duplicate keys found, skipping deduplication.\n",
      "\n",
      "STEP 3: Filtering outliers using IQR method\n",
      "   - Processing outliers for numeric column 'age'\n",
      "     Removed 174 outliers from 'age'\n",
      "     New row count: 10126\n",
      "   - Processing outliers for numeric column 'monthly_spend'\n",
      "     Removed 513 outliers from 'monthly_spend'\n",
      "     New row count: 9613\n",
      "   - Processing outliers for numeric column 'household_size'\n",
      "     Removed 64 outliers from 'household_size'\n",
      "     New row count: 9549\n",
      "\n",
      "STEP 4: Pipeline completed for table: Users\n",
      "Final schema:\n",
      "root\n",
      " |-- user_id: string (nullable = false)\n",
      " |-- email: string (nullable = false)\n",
      " |-- first_name: string (nullable = false)\n",
      " |-- last_name: string (nullable = false)\n",
      " |-- gender: string (nullable = false)\n",
      " |-- country: string (nullable = false)\n",
      " |-- state_province: string (nullable = false)\n",
      " |-- city: string (nullable = false)\n",
      " |-- subscription_plan: string (nullable = false)\n",
      " |-- subscription_start_date: date (nullable = true)\n",
      " |-- is_active: boolean (nullable = true)\n",
      " |-- primary_device: string (nullable = false)\n",
      " |-- created_at: timestamp (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- monthly_spend: double (nullable = true)\n",
      " |-- household_size: double (nullable = true)\n",
      "\n",
      "\n",
      "========== Cleaning table: Watch_history ==========\n",
      "\n",
      "STEP 0: Starting data-cleaning pipeline...\n",
      "Initial row count: 105000\n",
      "\n",
      "STEP 1: Handling missing values\n",
      " - Imputing numerical columns: ['watch_duration_minutes', 'progress_percentage', 'user_rating']\n",
      "   Completed numerical imputation.\n",
      "   Row count after numeric imputation: 105000\n",
      " - Imputing categorical columns: ['session_id', 'user_id', 'movie_id', 'device_type', 'action', 'quality', 'location_country']\n",
      "   Filled missing values in 'session_id' with mode='session_016880'\n",
      "   Filled missing values in 'user_id' with mode='user_06554'\n",
      "   Filled missing values in 'movie_id' with mode='movie_0939'\n",
      "   Filled missing values in 'device_type' with mode='Desktop'\n",
      "   Filled missing values in 'action' with mode='started'\n",
      "   Filled missing values in 'quality' with mode='HD'\n",
      "   Filled missing values in 'location_country' with mode='USA'\n",
      "   Completed categorical imputation.\n",
      "   Row count after categorical imputation: 105000\n",
      "\n",
      "STEP 2: Removing duplicates\n",
      " - No suitable duplicate keys found, skipping deduplication.\n",
      "\n",
      "STEP 3: Filtering outliers using IQR method\n",
      "   - Processing outliers for numeric column 'watch_duration_minutes'\n",
      "     Removed 5464 outliers from 'watch_duration_minutes'\n",
      "     New row count: 99536\n",
      "   - Processing outliers for numeric column 'progress_percentage'\n",
      "     Removed 0 outliers from 'progress_percentage'\n",
      "     New row count: 99536\n",
      "   - Processing outliers for numeric column 'user_rating'\n",
      "     Removed 15002 outliers from 'user_rating'\n",
      "     New row count: 84534\n",
      "\n",
      "STEP 4: Pipeline completed for table: Watch_history\n",
      "Final schema:\n",
      "root\n",
      " |-- session_id: string (nullable = false)\n",
      " |-- user_id: string (nullable = false)\n",
      " |-- movie_id: string (nullable = false)\n",
      " |-- watch_date: date (nullable = true)\n",
      " |-- device_type: string (nullable = false)\n",
      " |-- action: string (nullable = false)\n",
      " |-- quality: string (nullable = false)\n",
      " |-- location_country: string (nullable = false)\n",
      " |-- is_download: boolean (nullable = true)\n",
      " |-- watch_duration_minutes: double (nullable = true)\n",
      " |-- progress_percentage: double (nullable = true)\n",
      " |-- user_rating: long (nullable = true)\n",
      "\n",
      "\n",
      "========== Cleaning table: Reviews ==========\n",
      "\n",
      "STEP 0: Starting data-cleaning pipeline...\n",
      "Initial row count: 15450\n",
      "\n",
      "STEP 1: Handling missing values\n",
      " - Imputing numerical columns: ['rating', 'helpful_votes', 'total_votes', 'sentiment_score']\n",
      "   Completed numerical imputation.\n",
      "   Row count after numeric imputation: 15450\n",
      " - Imputing categorical columns: ['review_id', 'user_id', 'movie_id', 'device_type', 'review_text', 'sentiment']\n",
      "   Filled missing values in 'review_id' with mode='review_014859'\n",
      "   Filled missing values in 'user_id' with mode='user_05784'\n",
      "   Filled missing values in 'movie_id' with mode='movie_0317'\n",
      "   Filled missing values in 'device_type' with mode='Mobile'\n",
      "   Filled missing values in 'review_text' with mode='This series is a masterpiece!'\n",
      "   Filled missing values in 'sentiment' with mode='positive'\n",
      "   Completed categorical imputation.\n",
      "   Row count after categorical imputation: 15450\n",
      "\n",
      "STEP 2: Removing duplicates\n",
      " - No suitable duplicate keys found, skipping deduplication.\n",
      "\n",
      "STEP 3: Filtering outliers using IQR method\n",
      "   - Processing outliers for numeric column 'rating'\n",
      "     Removed 0 outliers from 'rating'\n",
      "     New row count: 15450\n",
      "   - Processing outliers for numeric column 'helpful_votes'\n",
      "     Removed 159 outliers from 'helpful_votes'\n",
      "     New row count: 15291\n",
      "   - Processing outliers for numeric column 'total_votes'\n",
      "     Removed 425 outliers from 'total_votes'\n",
      "     New row count: 14866\n",
      "   - Processing outliers for numeric column 'sentiment_score'\n",
      "     Removed 122 outliers from 'sentiment_score'\n",
      "     New row count: 14744\n",
      "\n",
      "STEP 4: Pipeline completed for table: Reviews\n",
      "Final schema:\n",
      "root\n",
      " |-- review_id: string (nullable = false)\n",
      " |-- user_id: string (nullable = false)\n",
      " |-- movie_id: string (nullable = false)\n",
      " |-- review_date: date (nullable = true)\n",
      " |-- device_type: string (nullable = false)\n",
      " |-- is_verified_watch: boolean (nullable = true)\n",
      " |-- review_text: string (nullable = false)\n",
      " |-- sentiment: string (nullable = false)\n",
      " |-- rating: long (nullable = true)\n",
      " |-- helpful_votes: double (nullable = true)\n",
      " |-- total_votes: double (nullable = true)\n",
      " |-- sentiment_score: double (nullable = true)\n",
      "\n",
      "Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (IntegerType, LongType, FloatType, DoubleType, DecimalType, StringType)\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "\n",
    "def choose_duplicate_keys(df):\n",
    "    \"\"\"\n",
    "    Try to infer a reasonable key for dropDuplicates.\n",
    "    \"\"\"\n",
    "    candidates = [\n",
    "        (\"CustomerID\", \"InvoiceDate\"),            # retail example\n",
    "        (\"user_id\", \"timestamp\"),\n",
    "        (\"userId\", \"timestamp\"),\n",
    "        (\"userId\", \"movieId\", \"timestamp\"),\n",
    "    ]\n",
    "    for keys in candidates:\n",
    "        if all(k in df.columns for k in keys):\n",
    "            return list(keys)\n",
    "    return None\n",
    "\n",
    "\n",
    "def remove_outliers_iqr(df, cols, k=1.5):\n",
    "    for c in cols:\n",
    "        print(f\"   - Processing outliers for numeric column '{c}'\")\n",
    "\n",
    "        # skip if column is all nulls\n",
    "        non_null = df.select(F.count(F.col(c))).first()[0]\n",
    "        if non_null == 0:\n",
    "            print(f\"     Skipping '{c}' (no non-null values).\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            q1, q3 = df.approxQuantile(c, [0.25, 0.75], 0.01)\n",
    "        except Exception as e:\n",
    "            print(f\"     Skipping '{c}' (approxQuantile error: {e})\")\n",
    "            continue\n",
    "\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - k * iqr\n",
    "        upper = q3 + k * iqr\n",
    "\n",
    "        before = df.count()\n",
    "        df = df.filter((F.col(c) >= lower) & (F.col(c) <= upper))\n",
    "        after = df.count()\n",
    "\n",
    "        print(f\"     Removed {before - after} outliers from '{c}'\")\n",
    "        print(f\"     New row count: {after}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_table(name, df):\n",
    "    print(f\"\\n========== Cleaning table: {name} ==========\\n\")\n",
    "    print(\"STEP 0: Starting data-cleaning pipeline...\")\n",
    "    print(\"Initial row count:\", df.count())\n",
    "\n",
    "    # Detect numeric and categorical columns for this table\n",
    "    numeric_cols = [\n",
    "        f.name for f in df.schema.fields\n",
    "        if isinstance(f.dataType, (IntegerType, LongType, FloatType, DoubleType, DecimalType))\n",
    "    ]\n",
    "    categorical_cols = [\n",
    "        f.name for f in df.schema.fields\n",
    "        if isinstance(f.dataType, StringType)\n",
    "    ]\n",
    "\n",
    "    # =========================================\n",
    "    # 1. Handling missing values (imputation)\n",
    "    # =========================================\n",
    "    print(\"\\nSTEP 1: Handling missing values\")\n",
    "\n",
    "    # a) Numerical columns\n",
    "    if numeric_cols:\n",
    "        print(\" - Imputing numerical columns:\", numeric_cols)\n",
    "\n",
    "        imputer = Imputer(\n",
    "            inputCols=numeric_cols,\n",
    "            outputCols=[c + \"_imputed\" for c in numeric_cols]\n",
    "        ).setStrategy(\"median\")\n",
    "\n",
    "        df = imputer.fit(df).transform(df)\n",
    "\n",
    "        for c in numeric_cols:\n",
    "            df = df.drop(c).withColumnRenamed(c + \"_imputed\", c)\n",
    "\n",
    "        print(\"   Completed numerical imputation.\")\n",
    "        print(\"   Row count after numeric imputation:\", df.count())\n",
    "    else:\n",
    "        print(\" - No numerical columns found for imputation.\")\n",
    "\n",
    "    # b) Categorical columns\n",
    "    if categorical_cols:\n",
    "        print(\" - Imputing categorical columns:\", categorical_cols)\n",
    "\n",
    "        for c in categorical_cols:\n",
    "            mode_row = (\n",
    "                df.groupBy(c)\n",
    "                  .count()\n",
    "                  .orderBy(F.desc(\"count\"))\n",
    "                  .first()\n",
    "            )\n",
    "            mode_value = mode_row[0] if mode_row else None\n",
    "            if mode_value is not None:\n",
    "                df = df.fillna({c: mode_value})\n",
    "                print(f\"   Filled missing values in '{c}' with mode='{mode_value}'\")\n",
    "\n",
    "        print(\"   Completed categorical imputation.\")\n",
    "        print(\"   Row count after categorical imputation:\", df.count())\n",
    "    else:\n",
    "        print(\" - No categorical (string) columns found for imputation.\")\n",
    "\n",
    "    # =========================================\n",
    "    # 2. Removing duplicates\n",
    "    # =========================================\n",
    "    print(\"\\nSTEP 2: Removing duplicates\")\n",
    "\n",
    "    dup_keys = choose_duplicate_keys(df)\n",
    "    if dup_keys:\n",
    "        print(f\" - Using keys for duplicates: {dup_keys}\")\n",
    "        before = df.count()\n",
    "        df = df.dropDuplicates(dup_keys)\n",
    "        after = df.count()\n",
    "        print(f\"   Removed {before - after} duplicates\")\n",
    "        print(\"   Row count after deduplication:\", after)\n",
    "    else:\n",
    "        print(\" - No suitable duplicate keys found, skipping deduplication.\")\n",
    "\n",
    "    # =========================================\n",
    "    # 3. Outlier filtering\n",
    "    # =========================================\n",
    "    print(\"\\nSTEP 3: Filtering outliers using IQR method\")\n",
    "\n",
    "    if numeric_cols:\n",
    "        df = remove_outliers_iqr(df, numeric_cols)\n",
    "    else:\n",
    "        print(\" - No numeric columns, skipping outlier filtering.\")\n",
    "\n",
    "    # =========================================\n",
    "    # 4. Final output\n",
    "    # =========================================\n",
    "    print(\"\\nSTEP 4: Pipeline completed for table:\", name)\n",
    "    print(\"Final schema:\")\n",
    "    df.printSchema()\n",
    "\n",
    "    # print(\"\\nFinal preview:\")\n",
    "    # df.show(10, truncate=False)\n",
    "    return df\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Run cleaning for all opened tables in `tables`\n",
    "# ---------------------------------------------------\n",
    "cleaned_tables = {}\n",
    "for table_name, table_df in tables.items():\n",
    "    cleaned_tables[table_name] = clean_table(table_name, table_df)\n",
    "print(\"Done.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2ee56fe1-63c1-4f16-89d4-a3bd9f60ca33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'Movies_cleaned' aggregation to BigQuery...\n",
      "\n",
      "Loaded table: Movies_cleaned\n",
      "root\n",
      " |-- movie_id: string (nullable = false)\n",
      " |-- title: string (nullable = false)\n",
      " |-- content_type: string (nullable = false)\n",
      " |-- genre_primary: string (nullable = false)\n",
      " |-- genre_secondary: string (nullable = true)\n",
      " |-- rating: string (nullable = false)\n",
      " |-- language: string (nullable = false)\n",
      " |-- country_of_origin: string (nullable = false)\n",
      " |-- is_netflix_original: boolean (nullable = true)\n",
      " |-- added_to_platform: date (nullable = true)\n",
      " |-- content_warning: boolean (nullable = true)\n",
      " |-- release_year: long (nullable = true)\n",
      " |-- duration_minutes: double (nullable = true)\n",
      " |-- imdb_rating: double (nullable = true)\n",
      " |-- production_budget: double (nullable = true)\n",
      " |-- box_office_revenue: double (nullable = true)\n",
      " |-- number_of_seasons: double (nullable = true)\n",
      " |-- number_of_episodes: double (nullable = true)\n",
      "\n",
      "Writing 'Users_cleaned' aggregation to BigQuery...\n",
      "\n",
      "Loaded table: Users_cleaned\n",
      "root\n",
      " |-- user_id: string (nullable = false)\n",
      " |-- email: string (nullable = false)\n",
      " |-- first_name: string (nullable = false)\n",
      " |-- last_name: string (nullable = false)\n",
      " |-- gender: string (nullable = false)\n",
      " |-- country: string (nullable = false)\n",
      " |-- state_province: string (nullable = false)\n",
      " |-- city: string (nullable = false)\n",
      " |-- subscription_plan: string (nullable = false)\n",
      " |-- subscription_start_date: date (nullable = true)\n",
      " |-- is_active: boolean (nullable = true)\n",
      " |-- primary_device: string (nullable = false)\n",
      " |-- created_at: timestamp (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- monthly_spend: double (nullable = true)\n",
      " |-- household_size: double (nullable = true)\n",
      "\n",
      "Writing 'Watch_history_cleaned' aggregation to BigQuery...\n",
      "\n",
      "Loaded table: Watch_history_cleaned\n",
      "root\n",
      " |-- session_id: string (nullable = false)\n",
      " |-- user_id: string (nullable = false)\n",
      " |-- movie_id: string (nullable = false)\n",
      " |-- watch_date: date (nullable = true)\n",
      " |-- device_type: string (nullable = false)\n",
      " |-- action: string (nullable = false)\n",
      " |-- quality: string (nullable = false)\n",
      " |-- location_country: string (nullable = false)\n",
      " |-- is_download: boolean (nullable = true)\n",
      " |-- watch_duration_minutes: double (nullable = true)\n",
      " |-- progress_percentage: double (nullable = true)\n",
      " |-- user_rating: long (nullable = true)\n",
      "\n",
      "Writing 'Reviews_cleaned' aggregation to BigQuery...\n",
      "\n",
      "Loaded table: Reviews_cleaned\n",
      "root\n",
      " |-- review_id: string (nullable = false)\n",
      " |-- user_id: string (nullable = false)\n",
      " |-- movie_id: string (nullable = false)\n",
      " |-- review_date: date (nullable = true)\n",
      " |-- device_type: string (nullable = false)\n",
      " |-- is_verified_watch: boolean (nullable = true)\n",
      " |-- review_text: string (nullable = false)\n",
      " |-- sentiment: string (nullable = false)\n",
      " |-- rating: long (nullable = true)\n",
      " |-- helpful_votes: double (nullable = true)\n",
      " |-- total_votes: double (nullable = true)\n",
      " |-- sentiment_score: double (nullable = true)\n",
      "\n",
      "\n",
      "All aggregations written to BigQuery successfully!\n"
     ]
    }
   ],
   "source": [
    "# Write aggregated results to BigQuery\n",
    "for cleaned_table, df in cleaned_tables.items():\n",
    "    print(f\"Writing '{cleaned_table}_cleaned' aggregation to BigQuery...\")\n",
    "    \n",
    "    df.write.format('bigquery') \\\n",
    "        .option('table', f'{project_id}.{bq_dataset}.{cleaned_table}_cleaned') \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save()\n",
    "\n",
    "    print(f\"\\nLoaded table: {cleaned_table}_cleaned\")\n",
    "    df.printSchema()\n",
    "\n",
    "print(\"\\nAll aggregations written to BigQuery successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "12111a76-1cff-4dcf-8e8a-30c4168161a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
