{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a42757fd-9357-4121-a00b-c168529dc01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session started.\n",
      "\n",
      "Loaded table: movies_cleaned\n",
      "root\n",
      " |-- movie_id: string (nullable = false)\n",
      " |-- title: string (nullable = false)\n",
      " |-- content_type: string (nullable = false)\n",
      " |-- genre_primary: string (nullable = false)\n",
      " |-- genre_secondary: string (nullable = true)\n",
      " |-- release_year: string (nullable = false)\n",
      " |-- duration_minutes: string (nullable = false)\n",
      " |-- rating: string (nullable = false)\n",
      " |-- language: string (nullable = false)\n",
      " |-- country_of_origin: string (nullable = false)\n",
      " |-- imdb_rating: string (nullable = true)\n",
      " |-- production_budget: string (nullable = true)\n",
      " |-- box_office_revenue: string (nullable = true)\n",
      " |-- number_of_seasons: string (nullable = true)\n",
      " |-- number_of_episodes: string (nullable = true)\n",
      " |-- is_netflix_original: string (nullable = false)\n",
      " |-- added_to_platform: string (nullable = false)\n",
      " |-- content_warning: string (nullable = false)\n",
      "\n",
      "\n",
      "Loaded table: users_cleaned\n",
      "root\n",
      " |-- user_id: string (nullable = false)\n",
      " |-- email: string (nullable = false)\n",
      " |-- first_name: string (nullable = false)\n",
      " |-- last_name: string (nullable = false)\n",
      " |-- age: string (nullable = true)\n",
      " |-- gender: string (nullable = false)\n",
      " |-- country: string (nullable = false)\n",
      " |-- state_province: string (nullable = false)\n",
      " |-- city: string (nullable = false)\n",
      " |-- subscription_plan: string (nullable = false)\n",
      " |-- subscription_start_date: string (nullable = false)\n",
      " |-- is_active: string (nullable = false)\n",
      " |-- monthly_spend: string (nullable = true)\n",
      " |-- primary_device: string (nullable = false)\n",
      " |-- household_size: string (nullable = false)\n",
      " |-- created_at: string (nullable = false)\n",
      "\n",
      "\n",
      "Loaded table: watch_history_cleaned\n",
      "root\n",
      " |-- session_id: string (nullable = false)\n",
      " |-- user_id: string (nullable = false)\n",
      " |-- movie_id: string (nullable = false)\n",
      " |-- watch_date: string (nullable = false)\n",
      " |-- device_type: string (nullable = false)\n",
      " |-- watch_duration_minutes: string (nullable = true)\n",
      " |-- progress_percentage: string (nullable = true)\n",
      " |-- action: string (nullable = false)\n",
      " |-- quality: string (nullable = false)\n",
      " |-- location_country: string (nullable = false)\n",
      " |-- is_download: string (nullable = false)\n",
      " |-- user_rating: string (nullable = true)\n",
      "\n",
      "\n",
      "Loaded table: reviews_cleaned\n",
      "root\n",
      " |-- review_id: string (nullable = false)\n",
      " |-- user_id: string (nullable = false)\n",
      " |-- movie_id: string (nullable = false)\n",
      " |-- rating: string (nullable = false)\n",
      " |-- review_date: string (nullable = false)\n",
      " |-- device_type: string (nullable = false)\n",
      " |-- is_verified_watch: string (nullable = false)\n",
      " |-- helpful_votes: string (nullable = false)\n",
      " |-- total_votes: string (nullable = false)\n",
      " |-- review_text: string (nullable = false)\n",
      " |-- sentiment: string (nullable = false)\n",
      " |-- sentiment_score: string (nullable = true)\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import avg, col, count, desc\n",
    "\n",
    "# =========================================\n",
    "# 0. START SPARK SESSION\n",
    "# =========================================\n",
    "\n",
    "# Configuration\n",
    "project_id = \"dejadsgl\"\n",
    "bq_dataset = \"netflix\"\n",
    "temp_bucket = \"netflix-group5-temp_gl\"\n",
    "data_bucket = \"netflix-group5-data_gl\"\n",
    "gcs_data_bucket = \"netflix_data_25\"\n",
    "\n",
    "# Spark configuration\n",
    "sparkConf = SparkConf()\n",
    "sparkConf.setMaster(\"spark://spark-master:7077\")\n",
    "sparkConf.setAppName(\"SparkIntegrationDataset\")\n",
    "sparkConf.set(\"spark.driver.memory\", \"2g\")\n",
    "sparkConf.set(\"spark.executor.cores\", \"1\")\n",
    "sparkConf.set(\"spark.driver.cores\", \"1\")\n",
    "\n",
    "# Create the Spark session\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "\n",
    "# Use the Cloud Storage bucket for temporary BigQuery export data used by the connector\n",
    "spark.conf.set('temporaryGcsBucket', temp_bucket)\n",
    "\n",
    "# Setup hadoop fs configuration for schema gs://\n",
    "conf = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "conf.set(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "\n",
    "print(\"Spark session started.\")\n",
    "\n",
    "# =========================================\n",
    "# 1. LOAD ALL TABLES\n",
    "# =========================================\n",
    "\n",
    "# Load data from BigQuery\n",
    "tables = {}\n",
    "titles = [\n",
    "    \"movies_cleaned\",\n",
    "    \"users_cleaned\",\n",
    "    \"watch_history_cleaned\",\n",
    "    \"reviews_cleaned\"\n",
    "]\n",
    "\n",
    "for title in titles:\n",
    "    df = spark.read \\\n",
    "            .format(\"bigquery\") \\\n",
    "            .load(f\"{project_id}.{bq_dataset}.{title}\")\n",
    "\n",
    "    df.cache()\n",
    "    tables[title] = df   # store in dictionary\n",
    "\n",
    "    print(f\"\\nLoaded table: {title}\")\n",
    "    df.printSchema()\n",
    "\n",
    "print(\"\\nDONE: Session started and table are loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f42bb7-206c-40e8-b1d6-45ba84ddb956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count in df: 15450\n",
      "Columns: ['review_id', 'user_id', 'movie_id', 'rating', 'review_date', 'device_type', 'is_verified_watch', 'helpful_votes', 'total_votes', 'review_text', 'sentiment', 'sentiment_score']\n",
      "\n",
      "STEP 3: Adding rating-based sentiment\n",
      "+----------+----------+------+----------------------+----------------------+\n",
      "|user_id   |movie_id  |rating|rating_sentiment_score|rating_sentiment_label|\n",
      "+----------+----------+------+----------------------+----------------------+\n",
      "|user_09061|movie_0460|5     |1.0                   |positive              |\n",
      "|user_01053|movie_0898|4     |0.5                   |positive              |\n",
      "|user_02136|movie_0514|3     |0.0                   |neutral               |\n",
      "|user_06521|movie_0682|3     |0.0                   |neutral               |\n",
      "|user_08539|movie_0803|5     |1.0                   |positive              |\n",
      "|user_07368|movie_0864|4     |0.5                   |positive              |\n",
      "|user_08984|movie_0149|5     |1.0                   |positive              |\n",
      "|user_07685|movie_0811|4     |0.5                   |positive              |\n",
      "|user_01654|movie_0370|2     |-0.5                  |negative              |\n",
      "|user_06536|movie_0207|3     |0.0                   |neutral               |\n",
      "+----------+----------+------+----------------------+----------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "STEP 4: Building unified review dataset\n",
      "Unified dataset rows: 15450\n",
      "+-------------+----------+----------+-----------+-----------+-----------------+-----------------------------------------------------------+---------+---------------+------+----------------------+----------------------+-------------+-----------+\n",
      "|review_id    |user_id   |movie_id  |review_date|device_type|is_verified_watch|review_text                                                |sentiment|sentiment_score|rating|rating_sentiment_score|rating_sentiment_label|helpful_votes|total_votes|\n",
      "+-------------+----------+----------+-----------+-----------+-----------------+-----------------------------------------------------------+---------+---------------+------+----------------------+----------------------+-------------+-----------+\n",
      "|review_000035|user_09061|movie_0460|2025-05-11 |Mobile     |False            |Amazing show! Couldn't stop watching.                      |positive |NULL           |5     |1.0                   |positive              |0.0          |8.0        |\n",
      "|review_000179|user_01053|movie_0898|2024-02-22 |Tablet     |True             |Incredible story telling. Kept me engaged throughout.      |positive |NULL           |4     |0.5                   |positive              |0.0          |4.0        |\n",
      "|review_000215|user_02136|movie_0514|2025-08-27 |Mobile     |True             |It was okay. Nothing special.                              |neutral  |NULL           |3     |0.0                   |neutral               |0.0          |6.0        |\n",
      "|review_000389|user_06521|movie_0682|2024-07-16 |Tablet     |True             |Average movie. Some good moments.                          |neutral  |NULL           |3     |0.0                   |neutral               |0.0          |5.0        |\n",
      "|review_001002|user_08539|movie_0803|2025-05-28 |Smart TV   |True             |One of the best series I've ever watched. Highly recommend!|positive |NULL           |5     |1.0                   |positive              |0.0          |3.0        |\n",
      "|review_001518|user_07368|movie_0864|2024-01-19 |Mobile     |False            |Perfect blend of drama and action.                         |positive |NULL           |4     |0.5                   |positive              |0.0          |2.0        |\n",
      "|review_001635|user_08984|movie_0149|2024-04-10 |Smart TV   |True             |Absolutely loved this movie. Great acting and storyline.   |positive |NULL           |5     |1.0                   |positive              |0.0          |4.0        |\n",
      "|review_001680|user_07685|movie_0811|2024-10-16 |Smart TV   |True             |One of the best series I've ever watched. Highly recommend!|positive |NULL           |4     |0.5                   |positive              |0.0          |6.0        |\n",
      "|review_001692|user_01654|movie_0370|2024-02-21 |Mobile     |True             |Slow paced and boring.                                     |negative |NULL           |2     |-0.5                  |negative              |0.0          |12.0       |\n",
      "|review_002911|user_06536|movie_0207|2025-11-25 |Tablet     |True             |Average movie. Some good moments.                          |neutral  |NULL           |3     |0.0                   |neutral               |0.0          |3.0        |\n",
      "+-------------+----------+----------+-----------+-----------+-----------------+-----------------------------------------------------------+---------+---------------+------+----------------------+----------------------+-------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "DONE: df_viewing is ready.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# ============================================================\n",
    "# 3. USING ALREADY LOADED DATAFRAME df\n",
    "# ============================================================\n",
    "print(\"Row count in df:\", df.count())\n",
    "print(\"Columns:\", df.columns)\n",
    "\n",
    "# ============================================================\n",
    "# 4. SENTIMENT VIA rating (numerieke review-score)\n",
    "# ============================================================\n",
    "print(\"\\nSTEP 3: Adding rating-based sentiment\")\n",
    "\n",
    "rating_col = \"rating\"   # jouw numerieke rating-kolom\n",
    "\n",
    "df_with_sentiment = (\n",
    "    df\n",
    "    .withColumn(\n",
    "        \"rating_sentiment_score\",\n",
    "        (F.col(rating_col).cast(\"double\") - F.lit(3.0)) / F.lit(2.0)\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"rating_sentiment_label\",\n",
    "        F.when(F.col(rating_col) >= 4, \"positive\")\n",
    "         .when(F.col(rating_col) == 3, \"neutral\")\n",
    "         .otherwise(\"negative\")\n",
    "    )\n",
    ")\n",
    "\n",
    "df_with_sentiment.select(\n",
    "    \"user_id\", \"movie_id\", rating_col,\n",
    "    \"rating_sentiment_score\", \"rating_sentiment_label\"\n",
    ").show(10, truncate=False)\n",
    "\n",
    "# ============================================================\n",
    "# 5. CREATE UNIFIED REVIEW DATASET (ipv viewing)\n",
    "# ============================================================\n",
    "print(\"\\nSTEP 4: Building unified review dataset\")\n",
    "\n",
    "df_viewing = df_with_sentiment.select(\n",
    "    \"review_id\",\n",
    "    \"user_id\",\n",
    "    \"movie_id\",\n",
    "    \"review_date\",\n",
    "    \"device_type\",\n",
    "    \"is_verified_watch\",\n",
    "    \"review_text\",\n",
    "    \"sentiment\",          # tekst-sentiment\n",
    "    \"sentiment_score\",    # tekst-sentiment-score\n",
    "    rating_col,           # numerieke rating\n",
    "    \"rating_sentiment_score\",\n",
    "    \"rating_sentiment_label\",\n",
    "    \"helpful_votes\",\n",
    "    \"total_votes\"\n",
    ")\n",
    "\n",
    "print(\"Unified dataset rows:\", df_viewing.count())\n",
    "df_viewing.show(10, truncate=False)\n",
    "\n",
    "print(\"\\nDONE: df_viewing is ready.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80659d90-853e-470c-beda-ca36d16c899a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing df_viewing to BigQuery...\n",
      "DONE: Table written to BigQuery.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6. WRITING DATASET TO BIGQUERY\n",
    "# ============================================================\n",
    "\n",
    "print(\"Writing df_viewing to BigQuery...\")\n",
    "\n",
    "df_viewing.write \\\n",
    "    .format(\"bigquery\") \\\n",
    "    .option(\"writeMethod\", \"direct\") \\\n",
    "    .option(\"table\", f\"{project_id}.{bq_dataset}.unified_review_dataset\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()\n",
    "\n",
    "print(\"DONE: Table written to BigQuery.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d4075fc-ef9d-4822-be14-3687b93c8cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
