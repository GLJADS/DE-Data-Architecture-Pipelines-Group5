{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608a3e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import avg, col, count, desc\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "\n",
    "# =========================================\n",
    "# 0. START SPARK SESSION\n",
    "# =========================================\n",
    "\n",
    "# Configuration\n",
    "project_id = os.environ.get(\"PROJECT_ID\", \"dejadsgl\")\n",
    "bq_dataset = os.environ.get(\"BQ_DATASET\", \"netflix\")\n",
    "temp_bucket = os.environ.get(\"TEMP_BUCKET\", \"netflix-group5-temp_gl\")\n",
    "gcs_data_bucket = os.environ.get(\"GCS_DATA_BUCKET\", \"netflix_data_25\")\n",
    "\n",
    "# Spark configuration\n",
    "sparkConf = SparkConf()\n",
    "sparkConf.setMaster(os.getenv(\"SPARK_MASTER\", \"local[*]\"))\n",
    "sparkConf.setAppName(\"FeatureTables\")\n",
    "sparkConf.set(\"spark.driver.memory\", \"2g\")\n",
    "sparkConf.set(\"spark.executor.cores\", \"1\")\n",
    "sparkConf.set(\"spark.driver.cores\", \"1\")\n",
    "\n",
    "# Create the Spark session\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "\n",
    "# Use the Cloud Storage bucket for temporary BigQuery export data used by the connector\n",
    "spark.conf.set('temporaryGcsBucket', temp_bucket)\n",
    "\n",
    "# Setup hadoop fs configuration for schema gs://\n",
    "conf = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "conf.set(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "\n",
    "print(\"Spark session started.\")\n",
    "\n",
    "# =========================================\n",
    "# 1. LOAD ALL TABLES\n",
    "# =========================================\n",
    "\n",
    "# Load data from BigQuery\n",
    "df = spark.read \\\n",
    "            .format(\"bigquery\") \\\n",
    "            .load(f\"{project_id}.{bq_dataset}.unified_review_dataset\")\n",
    "print(f\"\\nLoaded table: unified_review_dataset\")\n",
    "df.printSchema()\n",
    "\n",
    "print(\"\\nDONE: session started and data loaded.\")\n",
    "# -------------------------------------------------------------------\n",
    "# A. CONTENT METRICS\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# =============================================================\n",
    "# A1. Total views per movie  (genre hebben we hier niet)\n",
    "# =============================================================\n",
    "total_views_per_movie = (\n",
    "    df\n",
    "    .groupBy(\"movie_id\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"total_reviews\"),\n",
    "        F.sum(F.when(F.col(\"is_verified_watch\") == True, 1).otherwise(0)).alias(\"verified_reviews\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Resultaat bekijken:\n",
    "total_views_per_movie.show(10, truncate=False)\n",
    "\n",
    "# =============================================================\n",
    "# A2. Average completion rate (proxy: gemiddelde rating)\n",
    "# =============================================================\n",
    "average_completion_proxy = (\n",
    "    df\n",
    "    .groupBy(\"movie_id\")\n",
    "    .agg(\n",
    "        F.avg(\"rating\").alias(\"avg_rating\"),\n",
    "        F.avg(\"sentiment_score\").alias(\"avg_text_sentiment_score\")\n",
    "    )\n",
    ")\n",
    "\n",
    "average_completion_proxy.show(10, truncate=False)\n",
    "\n",
    "# =============================================================\n",
    "# A3. Popularity trends (daily & weekly) op basis van review-volume\n",
    "# =============================================================\n",
    "\n",
    "# Daily: aantal reviews per film per dag\n",
    "popularity_daily = (\n",
    "    df\n",
    "    .groupBy(\"movie_id\", \"review_date\")\n",
    "    .agg(F.count(\"*\").alias(\"daily_reviews\"))\n",
    ")\n",
    "\n",
    "popularity_daily.show(10, truncate=False)\n",
    "\n",
    "# Weekly: aantal reviews per film per week\n",
    "df_week = df.withColumn(\"week_start\", F.date_trunc(\"week\", F.col(\"review_date\")))\n",
    "\n",
    "popularity_weekly = (\n",
    "    df_week\n",
    "    .groupBy(\"movie_id\", \"week_start\")\n",
    "    .agg(F.count(\"*\").alias(\"weekly_reviews\"))\n",
    ")\n",
    "\n",
    "popularity_weekly.show(10, truncate=False)\n",
    "\n",
    "# =============================================================\n",
    "# A4. Regional preferences (USA vs Canada)\n",
    "# =============================================================\n",
    "# LET OP: de review dataset heeft GEEN land-kolom.\n",
    "# Deze query kan pas draaien als er bijvoorbeeld een kolom\n",
    "# 'location_country' is toegevoegt (via join met een user- of watch-tabel).\n",
    "\n",
    "# regional_preferences = (\n",
    "#     df\n",
    "#     .filter(F.col(\"location_country\").isin(\"USA\", \"Canada\"))\n",
    "#     .groupBy(\"movie_id\", \"location_country\")\n",
    "#     .agg(F.count(\"*\").alias(\"total_reviews\"))\n",
    "# )\n",
    "# regional_preferences.show(10, truncate=False)\n",
    "\n",
    "# =============================================================\n",
    "# A5. Device-specific performance\n",
    "# =============================================================\n",
    "\n",
    "device_specific_performance = (\n",
    "    df\n",
    "    .groupBy(\"device_type\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"total_reviews\"),\n",
    "        F.sum(F.when(F.col(\"is_verified_watch\") == True, 1).otherwise(0)).alias(\"verified_reviews\"),\n",
    "        F.avg(\"rating\").alias(\"avg_rating\"),\n",
    "        F.avg(\"sentiment_score\").alias(\"avg_sentiment_score\")\n",
    "    )\n",
    ")\n",
    "\n",
    "device_specific_performance.show(10, truncate=False)\n",
    "\n",
    "print(\"\\nDONE: Content Metrics\")\n",
    "# -------------------------------------------------------------------\n",
    "# B. User Engagement Metrics\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Basis: datum\n",
    "today = F.current_date()\n",
    "\n",
    "# =============================================================\n",
    "# B1. Days since last watch (laatste review)\n",
    "# =============================================================\n",
    "user_last_watch = (\n",
    "    df\n",
    "    .groupBy(\"user_id\")\n",
    "    .agg(F.max(\"review_date\").alias(\"last_review_date\"))\n",
    "    .withColumn(\n",
    "        \"days_since_last_watch\",\n",
    "        F.datediff(today, \"last_review_date\")\n",
    "    )\n",
    ")\n",
    "\n",
    "user_last_watch.show(10, truncate=False)\n",
    "\n",
    "# =============================================================\n",
    "# B2. Average daily watch time (7d, 30d rolling)\n",
    "#    → proxy: gemiddelde verified views per dag\n",
    "# =============================================================\n",
    "\n",
    "# 7 dagen terug (inclusief vandaag)\n",
    "last_7_days = df.filter(F.col(\"review_date\") >= F.date_sub(today, 6))\n",
    "# 30 dagen terug\n",
    "last_30_days = df.filter(F.col(\"review_date\") >= F.date_sub(today, 29))\n",
    "\n",
    "avg_watch_7d = (\n",
    "    last_7_days\n",
    "    .groupBy(\"user_id\")\n",
    "    .agg(\n",
    "        (\n",
    "            F.sum(F.when(F.col(\"is_verified_watch\") == True, 1).otherwise(0))\n",
    "            / F.lit(7)\n",
    "        ).alias(\"avg_daily_verified_views_7d\")\n",
    "    )\n",
    ")\n",
    "\n",
    "avg_watch_30d = (\n",
    "    last_30_days\n",
    "    .groupBy(\"user_id\")\n",
    "    .agg(\n",
    "        (\n",
    "            F.sum(F.when(F.col(\"is_verified_watch\") == True, 1).otherwise(0))\n",
    "            / F.lit(30)\n",
    "        ).alias(\"avg_daily_verified_views_30d\")\n",
    "    )\n",
    ")\n",
    "\n",
    "avg_watch_7d.show(10, truncate=False)\n",
    "avg_watch_30d.show(10, truncate=False)\n",
    "\n",
    "# =============================================================\n",
    "# B3. Binge-watching score\n",
    "#    → max verified views op één dag in laatste 30 dagen\n",
    "# =============================================================\n",
    "binge_base = (\n",
    "    last_30_days\n",
    "    .groupBy(\"user_id\", \"review_date\")\n",
    "    .agg(\n",
    "        F.sum(F.when(F.col(\"is_verified_watch\") == True, 1).otherwise(0))\n",
    "         .alias(\"verified_views_per_day\")\n",
    "    )\n",
    ")\n",
    "\n",
    "binge_score = (\n",
    "    binge_base\n",
    "    .groupBy(\"user_id\")\n",
    "    .agg(F.max(\"verified_views_per_day\").alias(\"binge_watching_score\"))\n",
    ")\n",
    "\n",
    "binge_score.show(10, truncate=False)\n",
    "\n",
    "# =============================================================\n",
    "# B4. Content diversity index\n",
    "#    → (# unieke films) / (# verified views) in laatste 30 dagen\n",
    "# =============================================================\n",
    "diversity_base = (\n",
    "    last_30_days\n",
    "    .groupBy(\"user_id\")\n",
    "    .agg(\n",
    "        F.sum(F.when(F.col(\"is_verified_watch\") == True, 1).otherwise(0))\n",
    "         .alias(\"total_verified_views_30d\"),\n",
    "        F.countDistinct(\n",
    "            F.when(F.col(\"is_verified_watch\") == True, F.col(\"movie_id\"))\n",
    "        ).alias(\"distinct_movies_30d\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"content_diversity_index\",\n",
    "        F.when(\n",
    "            F.col(\"total_verified_views_30d\") > 0,\n",
    "            F.col(\"distinct_movies_30d\") / F.col(\"total_verified_views_30d\")\n",
    "        ).otherwise(F.lit(0.0))\n",
    "    )\n",
    ")\n",
    "\n",
    "diversity_base.select(\n",
    "    \"user_id\", \"total_verified_views_30d\",\n",
    "    \"distinct_movies_30d\", \"content_diversity_index\"\n",
    ").show(10, truncate=False)\n",
    "\n",
    "# =============================================================\n",
    "# B5. Engagement trend (increasing / decreasing)\n",
    "#    → compare verified views last_7 vs previous_7 days\n",
    "# =============================================================\n",
    "\n",
    "last_14_days = df.filter(F.col(\"review_date\") >= F.date_sub(today, 13))\n",
    "\n",
    "eng_base = (\n",
    "    last_14_days\n",
    "    .withColumn(\n",
    "        \"period\",\n",
    "        F.when(F.col(\"review_date\") >= F.date_sub(today, 6), \"last_7\")\n",
    "         .otherwise(\"prev_7\")\n",
    "    )\n",
    "    .groupBy(\"user_id\", \"period\")\n",
    "    .agg(\n",
    "        F.sum(F.when(F.col(\"is_verified_watch\") == True, 1).otherwise(0))\n",
    "         .alias(\"verified_views\")\n",
    "    )\n",
    ")\n",
    "\n",
    "eng_trend = (\n",
    "    eng_base\n",
    "    .groupBy(\"user_id\")\n",
    "    .pivot(\"period\", [\"prev_7\", \"last_7\"])\n",
    "    .agg(F.first(\"verified_views\"))\n",
    "    .fillna(0, subset=[\"prev_7\", \"last_7\"])\n",
    "    .withColumn(\n",
    "        \"engagement_change_pct\",\n",
    "        F.when(\n",
    "            F.col(\"prev_7\") > 0,\n",
    "            (F.col(\"last_7\") - F.col(\"prev_7\")) / F.col(\"prev_7\")\n",
    "        ).otherwise(F.lit(None))\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"engagement_trend\",\n",
    "        F.when(F.col(\"engagement_change_pct\") > 0.1, \"increasing\")\n",
    "         .when(F.col(\"engagement_change_pct\") < -0.1, \"decreasing\")\n",
    "         .otherwise(\"stable\")\n",
    "    )\n",
    ")\n",
    "\n",
    "eng_trend.show(10, truncate=False)\n",
    "\n",
    "print(\"\\nDONE: User Engagement Metrics\")\n",
    "# -------------------------------------------------------------------\n",
    "# C. Churn Risk Indicators\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# =============================================================\n",
    "# C1. Viewing frequency drop > 50%\n",
    "#    → vergelijk verified views in vorige 7 dagen vs laatste 7 dagen\n",
    "# =============================================================\n",
    "\n",
    "last_14_days = df.filter(F.col(\"review_date\") >= F.date_sub(today, 13))\n",
    "\n",
    "freq_base = (\n",
    "    last_14_days\n",
    "    .withColumn(\n",
    "        \"period\",\n",
    "        F.when(F.col(\"review_date\") >= F.date_sub(today, 6), \"last_7\")\n",
    "         .otherwise(\"prev_7\")\n",
    "    )\n",
    "    .groupBy(\"user_id\", \"period\")\n",
    "    .agg(\n",
    "        F.sum(F.when(F.col(\"is_verified_watch\") == True, 1).otherwise(0))\n",
    "         .alias(\"verified_views\")\n",
    "    )\n",
    ")\n",
    "\n",
    "freq_pivot = (\n",
    "    freq_base\n",
    "    .groupBy(\"user_id\")\n",
    "    .pivot(\"period\", [\"prev_7\", \"last_7\"])\n",
    "    .agg(F.first(\"verified_views\"))\n",
    "    .fillna(0, subset=[\"prev_7\", \"last_7\"])\n",
    "    .withColumn(\n",
    "        \"engagement_change_pct\",\n",
    "        F.when(\n",
    "            F.col(\"prev_7\") > 0,\n",
    "            (F.col(\"last_7\") - F.col(\"prev_7\")) / F.col(\"prev_7\")\n",
    "        ).otherwise(F.lit(None))\n",
    "    )\n",
    ")\n",
    "\n",
    "churn_freq_drop = (\n",
    "    freq_pivot\n",
    "    .withColumn(\n",
    "        \"freq_drop_gt_50pct\",\n",
    "        F.col(\"engagement_change_pct\") < -0.5\n",
    "    )\n",
    ")\n",
    "\n",
    "churn_freq_drop.show(10, truncate=False)\n",
    "\n",
    "# =============================================================\n",
    "# C2. No activity in 7+ days\n",
    "#    → laatste review ouder dan 7 dagen\n",
    "# =============================================================\n",
    "\n",
    "user_last_watch = (\n",
    "    df\n",
    "    .groupBy(\"user_id\")\n",
    "    .agg(F.max(\"review_date\").alias(\"last_review_date\"))\n",
    "    .withColumn(\n",
    "        \"days_since_last_watch\",\n",
    "        F.datediff(today, \"last_review_date\")\n",
    "    )\n",
    ")\n",
    "\n",
    "churn_no_activity = (\n",
    "    user_last_watch\n",
    "    .withColumn(\n",
    "        \"no_activity_7_plus_days\",\n",
    "        F.col(\"days_since_last_watch\") >= 7\n",
    "    )\n",
    ")\n",
    "\n",
    "churn_no_activity.show(10, truncate=False)\n",
    "\n",
    "# =============================================================\n",
    "# C3. Declining completion rates\n",
    "#    → proxy: dalende gemiddelde rating (laatste 7 vs vorige 7 dagen)\n",
    "# =============================================================\n",
    "\n",
    "ratings_last_14 = (\n",
    "    last_14_days\n",
    "    .withColumn(\n",
    "        \"period\",\n",
    "        F.when(F.col(\"review_date\") >= F.date_sub(today, 6), \"last_7\")\n",
    "         .otherwise(\"prev_7\")\n",
    "    )\n",
    "    .groupBy(\"user_id\", \"period\")\n",
    "    .agg(F.avg(\"rating\").alias(\"avg_rating\"))\n",
    ")\n",
    "\n",
    "ratings_pivot = (\n",
    "    ratings_last_14\n",
    "    .groupBy(\"user_id\")\n",
    "    .pivot(\"period\", [\"prev_7\", \"last_7\"])\n",
    "    .agg(F.first(\"avg_rating\"))\n",
    ")\n",
    "\n",
    "churn_declining_completion = (\n",
    "    ratings_pivot\n",
    "    .withColumn(\"rating_change\", F.col(\"last_7\") - F.col(\"prev_7\"))\n",
    "    .withColumn(\n",
    "        \"declining_completion_rate\",\n",
    "        F.col(\"rating_change\") < 0\n",
    "    )\n",
    ")\n",
    "\n",
    "churn_declining_completion.show(10, truncate=False)\n",
    "\n",
    "# =============================================================\n",
    "# C4. Negative review patterns\n",
    "#    → > 50% negatieve reviews in laatste 90 dagen\n",
    "# =============================================================\n",
    "\n",
    "reviews_90d = df.filter(F.col(\"review_date\") >= F.date_sub(today, 89))\n",
    "\n",
    "neg_review_patterns = (\n",
    "    reviews_90d\n",
    "    .groupBy(\"user_id\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"total_reviews_90d\"),\n",
    "        F.sum(F.when(F.col(\"sentiment\") == \"negative\", 1).otherwise(0))\n",
    "         .alias(\"negative_reviews_90d\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"negative_review_ratio\",\n",
    "        F.when(\n",
    "            F.col(\"total_reviews_90d\") > 0,\n",
    "            F.col(\"negative_reviews_90d\") / F.col(\"total_reviews_90d\")\n",
    "        ).otherwise(F.lit(0.0))\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"negative_review_pattern\",\n",
    "        F.col(\"negative_review_ratio\") > 0.5\n",
    "    )\n",
    ")\n",
    "\n",
    "neg_review_patterns.show(10, truncate=False)\n",
    "\n",
    "print(\"\\nDONE: Churn Risk Indicators\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879a24be-87cb-4fc0-94c9-57a48fa85021",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
